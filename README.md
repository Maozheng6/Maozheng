# Andrew (Maozheng) Zhao [Resume](Resume_Andrew.pdf)
[Resume](Resume_Andrew.pdf) \|
[LinkedIn](https://www.linkedin.com/in/andrew-maozheng-z-51079914a/) \|
[Google scholar](https://scholar.google.com/citations?hl=en&user=3wbgHbIAAAAJ)
<br/>

## About me
<img align="left" src="opt_head.jpg" width="150">  

I completed my Ph.D. in Computer Science, advised by Prof. [Xiaojun Bi](https://www3.cs.stonybrook.edu/~xiaojun/) in the Human-computer Interaction Lab at [Stony Brook University](https://www.stonybrook.edu/). My research focuses on intelligent multimodal input technologies on mobile devices. I integrated multiple input modalities, such as touch, voice, and eye gaze, with AI models for a more efficient and natural interaction experience. Iâ€™m experienced with Android, iOS, and Unity development, as well as LLM finetuning and computer vision.
<br/><br/><br/>

## Internship experience

**Research Scientist Intern, Meta, Redmond, WA**<br/>
May 2022 - Sept 2022<br/>
Built a multi-modal gesture input application in virtual reality using wristband and eye gaze as input. It reduced 30% movement burden for users. The project is published in IUI 2023. <br/>
<br/>
**Research Intern, Google, Mountain View, CA**<br/>
Oct 2022 - Dec 2022<br/>
Fine-tuned LLMs to enable Android settings search to understand natural language queries. The fine-tuned LLMs outperform traditional search methods such as TF-IDF, sentence encoding, and prompt engineering.<br/>
<br/>
**Student researcher, Google, Mountain View, CA**<br/>
Dec, 2022 - May, 2023<br/> 


## Selected publications


<img align="right" src="llm_teaser.png" width="250">  

### LLM-VT: LLM-based Noise-robust Case-sensitive Text Correction System on Smartphones with Voice and Touch Input <br/>
**Maozheng Zhao**, Nathan Huang, Rui Liu, Michael Xuelin Huang, Shumin Zhai, I. V. Ramakrishnan, and Xiaojun Bi <br/>
Submitted to Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (**IMWUT**), 2024 <br/>
[Webpage](https://maozheng6.github.io/LLM-VT/)

#

<a href="https://maozheng6.github.io/VT/"><img align="right" src="VT_teaser.png" width="250" >  
### Voice and Touch Based Error-tolerant Multimodal Text Editing and Correction for Smartphones
**Maozheng Zhao**, Wenzhe Cui, I. V. Ramakrishnan, Shumin Zhai, and Xiaojun Bi <br/>
ACM Symposium on User Interface Software and Technology (**UIST**), 2021. [Acceptance Rate: 25.05%]  <br/>
[Webpage](https://maozheng6.github.io/VT/), <a href="https://dl.acm.org/doi/pdf/10.1145/3472749.3474742"><img  src="pdf.gif" width="20" >  [Paper](https://dl.acm.org/doi/pdf/10.1145/3472749.3474742) <br/>
#

<a href="https://maozheng6.github.io/GazeSpeedup/"><img align="right" src="gc_teaser.png" width="250" >  
### Gaze Speedup: Eye Gaze Assisted Gesture Typing in Virtual Reality
**Maozheng Zhao**, Alec M. Pierce, Ran Tan, Ting Zhang, Tianyi Wang, Tanya R. Jonker, Hrvoje Benko, and Aakar Gupta. <br/>
International Conference on Intelligent User Interfaces (**IUI**), 2023. [Acceptance Rate: 24.1%]  <br/>
[Project webpage](https://maozheng6.github.io/GazeSpeedup/), <a href="https://dl.acm.org/doi/pdf/10.1145/3581641.3584072"><img  src="pdf.gif" width="20" >  [Paper](https://dl.acm.org/doi/pdf/10.1145/3581641.3584072) <br/>
#

<a href="https://maozheng6.github.io/EyeSayCorrect/"><img align="right" src="ESC_teaser.png" width="250" >  

### EyeSayCorrect: Eye Gaze and Voice Based Hands-free Text Correction for Mobile Devices
**Maozheng Zhao**, Henry Huang, Zhi Li, Rui Liu, Wenzhe Cui, Kajal Toshniwal, Ananya Goel, et al.   <br/>
International Conference on Intelligent User Interfaces (**IUI**), 2022. [Acceptance Rate: 24.5%]   <br/>
[Project webpage](https://maozheng6.github.io/EyeSayCorrect/), <a href="https://dl.acm.org/doi/pdf/10.1145/3490099.3511103"><img  src="pdf.gif" width="20" >  [Paper](https://dl.acm.org/doi/pdf/10.1145/3490099.3511103) <br/>
#

<img align="right" src="sos.png" width="250" >  

### Select or Suggest? Reinforcement Learning-based Method for High-Accuracy Target Selection on Touchscreens
Li, Zhi, **Maozheng Zhao**, Dibyendu Das, Hang Zhao, Yan Ma, Wanyu Liu, Michel Beaudouin-Lafon, Fusheng Wang, Iv Ramakrishnan, and Xiaojun Bi.  <br/>
Conference on Human Factors in Computing Systems (**CHI**), 2022. [Acceptance Rate: 24.8%]  <br/>
<a href="https://maozheng6.github.io/Maozheng/SOS.pdf"><img  src="pdf.gif" width="20" >  [Paper](https://maozheng6.github.io/Maozheng/SOS.pdf) <br/>
#

<img align="right" src="bg.png" width="250" >  

### BayesGaze: A Bayesian Approach to Eye-Gaze Based Target Selection
Li, Zhi, **Maozheng Zhao**, Yifan Wang, Sina Rashidian, Furqan Baig, Rui Liu, Wanyu Liu et al. <br/>
Graphics Interface (**GI**), 2021. <br/>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8853835/"><img  src="pdf.gif" width="20" >  [Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8853835/) <br/>
#

<img align="right" src="gan.png" width="250" >  

### Shadow detection with conditional generative adversarial networks
Nguyen, Vu, Tomas F. Yago Vicente, **Maozheng Zhao**, Minh Hoai, and Dimitris Samaras. <br/>
IEEE International Conference on Computer Vision (**ICCV**), 2017. <br/>
<a href="https://maozheng6.github.io/Maozheng/scgan.pdf"><img  src="pdf.gif" width="20" >  [Paper](https://maozheng6.github.io/Maozheng/scgan.pdf) <br/> 
#


## Programming skills
Python, Java, Swift, C#, C++, PyTorch, TensorFlow, iOS development, Android development, Unity development


